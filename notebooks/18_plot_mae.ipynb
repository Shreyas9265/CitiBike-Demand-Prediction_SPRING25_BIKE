{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a75bb5-92f2-4a5e-a4f5-ba8daa9eb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b71af71-2fd3-4c10-9a22-59fefa557202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5bbc08-f5b5-4813-88ae-755e0aa9a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from src.inference import get_feature_store, fetch_predictions\n",
    "\n",
    "def fetch_hourly_rides(hours):\n",
    "    current_hour = (pd.Timestamp.now(tz=\"Etc/UTC\") - timedelta(hours=hours)).floor('h')\n",
    "\n",
    "    fs = get_feature_store()\n",
    "    fg = fs.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=1\n",
    "    )\n",
    "\n",
    "    query = fg.select_all()\n",
    "    query = query.filter(fg.pickup_hour >= current_hour)\n",
    "\n",
    "    return query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e6ac55-5c48-4ca7-92cf-a31efd0213fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:41:20,698 INFO: Initializing external client\n",
      "2025-05-09 11:41:20,699 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-09 11:41:22,620 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214627\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.85s) \n"
     ]
    }
   ],
   "source": [
    "df = fetch_hourly_rides(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98f6519-87e4-412a-915d-e40f780ba2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-09 06:00:00+00:00</td>\n",
       "      <td>5282.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-09 09:00:00+00:00</td>\n",
       "      <td>JC095</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-09 00:00:00+00:00</td>\n",
       "      <td>HB302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-09 07:00:00+00:00</td>\n",
       "      <td>7260.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-09 15:00:00+00:00</td>\n",
       "      <td>HB505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>2025-05-09 10:00:00+00:00</td>\n",
       "      <td>JC104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2025-05-09 06:00:00+00:00</td>\n",
       "      <td>JC057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2025-05-09 04:00:00+00:00</td>\n",
       "      <td>JC002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2025-05-09 09:00:00+00:00</td>\n",
       "      <td>JC009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2025-05-09 14:00:00+00:00</td>\n",
       "      <td>JC077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1564 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pickup_hour pickup_location_id  rides\n",
       "0    2025-05-09 06:00:00+00:00            5282.02      0\n",
       "1    2025-05-09 09:00:00+00:00              JC095      2\n",
       "2    2025-05-09 00:00:00+00:00              HB302      0\n",
       "3    2025-05-09 07:00:00+00:00            7260.09      0\n",
       "4    2025-05-09 15:00:00+00:00              HB505      0\n",
       "...                        ...                ...    ...\n",
       "1559 2025-05-09 10:00:00+00:00              JC104      1\n",
       "1560 2025-05-09 06:00:00+00:00              JC057      2\n",
       "1561 2025-05-09 04:00:00+00:00              JC002      0\n",
       "1562 2025-05-09 09:00:00+00:00              JC009      3\n",
       "1563 2025-05-09 14:00:00+00:00              JC077      0\n",
       "\n",
       "[1564 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726c8f81-57e4-4b4b-b1e1-76bd93a0c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:41:29,354 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-09 11:41:29,370 INFO: Initializing external client\n",
      "2025-05-09 11:41:29,371 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-09 11:41:30,917 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214627\n",
      "2025-05-09 11:41:32,987 ERROR: No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:\"2025-05-09T15:41:32.8900039+00:00\", grpc_status:2, grpc_message:\"No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 394, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 459, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py\", line 257, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\six.py\", line 724, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peddi\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 445, in _get_dataset\n",
      "    reader = self._connection.do_get(info.endpoints[0].ticket, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 1708, in pyarrow._flight.FlightClient.do_get\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 58, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightServerError: No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:\"2025-05-09T15:41:32.8900039+00:00\", grpc_status:2, grpc_message:\"No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:\"2025-05-09T15:41:32.8900039+00:00\", grpc_status:2, grpc_message:\"No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFlightServerError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:394\u001b[39m, in \u001b[36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[39m\u001b[34m(instance, *args, **kw)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:459\u001b[39m, in \u001b[36mArrowFlightClient.read_query\u001b[39m\u001b[34m(self, query_object, arrow_flight_config, dataframe_type)\u001b[39m\n\u001b[32m    458\u001b[39m descriptor = pyarrow.flight.FlightDescriptor.for_command(query_encoded)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimeout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrow_flight_config\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py:56\u001b[39m, in \u001b[36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@six\u001b[39m.wraps(f)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_f\u001b[39m(*args, **kw):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py:257\u001b[39m, in \u001b[36mRetrying.call\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.should_reject(attempt):\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._after_attempts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py:301\u001b[39m, in \u001b[36mAttempt.get\u001b[39m\u001b[34m(self, wrap_exception)\u001b[39m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m         \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\six.py:724\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m    723\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\retrying.py:251\u001b[39m, in \u001b[36mRetrying.call\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     attempt = Attempt(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:445\u001b[39m, in \u001b[36mArrowFlightClient._get_dataset\u001b[39m\u001b[34m(self, descriptor, timeout, dataframe_type)\u001b[39m\n\u001b[32m    442\u001b[39m options = pyarrow.flight.FlightCallOptions(\n\u001b[32m    443\u001b[39m     timeout=timeout, headers=\u001b[38;5;28mself\u001b[39m._certificates_headers()\n\u001b[32m    444\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mticket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m _logger.debug(\u001b[33m\"\u001b[39m\u001b[33mDataset fetched. Converting to dataframe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, dataframe_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\pyarrow\\_flight.pyx:1708\u001b[39m, in \u001b[36mpyarrow._flight.FlightClient.do_get\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\pyarrow\\_flight.pyx:58\u001b[39m, in \u001b[36mpyarrow._flight.check_flight_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFlightServerError\u001b[39m: No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:\"2025-05-09T15:41:32.8900039+00:00\", grpc_status:2, grpc_message:\"No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFeatureStoreException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_pred = \u001b[43mfetch_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\AML_PROJECT4\\citi_bike_zip\\src\\inference.py:108\u001b[39m, in \u001b[36mfetch_predictions\u001b[39m\u001b[34m(hours)\u001b[39m\n\u001b[32m    105\u001b[39m fs = get_feature_store()\n\u001b[32m    106\u001b[39m fg = fs.get_feature_group(name=config.FEATURE_GROUP_MODEL_PREDICTION, version=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m df = \u001b[43mfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpickup_hour\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_hour\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\constructor\\query.py:305\u001b[39m, in \u001b[36mQuery.read\u001b[39m\u001b[34m(self, online, dataframe_type, read_options)\u001b[39m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.joins) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [f.type \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m schema]:\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    302\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPandas types casting only supported for feature_group.read()/query.select_all()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    303\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_store_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43monline_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\engine\\python.py:146\u001b[39m, in \u001b[36mEngine.sql\u001b[39m\u001b[34m(self, sql_query, feature_store, online_conn, dataframe_type, read_options, schema)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msql\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    138\u001b[39m     sql_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m     schema: Optional[List[feature.Feature]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    144\u001b[39m ) -> Union[pd.DataFrame, pl.DataFrame]:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m online_conn:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sql_offline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m            \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marrow_flight_config\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jdbc(\n\u001b[32m    156\u001b[39m             sql_query, online_conn, dataframe_type, read_options, schema\n\u001b[32m    157\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\engine\\python.py:189\u001b[39m, in \u001b[36mEngine._sql_offline\u001b[39m\u001b[34m(self, sql_query, dataframe_type, schema, arrow_flight_config)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql_query, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mquery_string\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sql_query:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhsfs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m arrow_flight_client\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     result_df = \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_with_loading_animation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReading data from Hopsworks, using Hopsworks Feature Query Service\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43marrow_flight_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReading data with Hive is not supported when using hopsworks client version >= 4.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hopsworks_common\\util.py:348\u001b[39m, in \u001b[36mrun_with_loading_animation\u001b[39m\u001b[34m(message, func, *args, **kwargs)\u001b[39m\n\u001b[32m    345\u001b[39m end = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     end = time.time()\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sp25_bike\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:410\u001b[39m, in \u001b[36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[39m\u001b[34m(instance, *args, **kw)\u001b[39m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[32m    407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mHopsworks Query Service is busy right now. Please try again later.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_no_commits_found_error(e):\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\u001b[38;5;28mstr\u001b[39m(e).split(\u001b[33m\"\u001b[39m\u001b[33mDetails:\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(user_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mFeatureStoreException\u001b[39m: No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:\"2025-05-09T15:41:32.8900039+00:00\", grpc_status:2, grpc_message:\"No commits found for featuregroup: /apps/hive/warehouse/spring25_taxi_featurestore.db/citi_bike_hourly_model_prediction_1. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal"
     ]
    }
   ],
   "source": [
    "df_pred = fetch_predictions(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc39644-1a5f-43f4-90cc-68569eb1dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da8ce0-0e5f-45ca-a513-7508338ce335",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_pred, on=['pickup_location_id', 'pickup_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d120e77-037f-42bb-90d9-33346c9e8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2183a04-85b3-4a12-9344-c8efbd413612",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['difference'] = merged_df['predicted_demand'] - merged_df['rides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5a44d-8f68-405b-a595-07fb7575ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values([\"pickup_location_id\", \"pickup_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681c57f-cf0b-4094-bf6c-6d2a9c4aa639",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf710c60-1e82-46f6-a967-0226192334b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import plotly.express as px\n",
    "df1 = df\n",
    "df2 = df_pred\n",
    "\n",
    "# Merge the DataFrames on 'pickup_location_id' and 'pickup_hour'  \n",
    "merged_df = pd.merge(df1, df2, on=['pickup_location_id', 'pickup_hour'])  \n",
    "\n",
    "# Calculate the absolute error  \n",
    "merged_df['absolute_error'] = abs(merged_df['predicted_demand'] - merged_df['rides'])  \n",
    "\n",
    "# Group by 'pickup_hour' and calculate the mean absolute error (MAE)  \n",
    "mae_by_hour = merged_df.groupby('pickup_hour')['absolute_error'].mean().reset_index()  \n",
    "mae_by_hour.rename(columns={'absolute_error': 'MAE'}, inplace=True)  \n",
    "\n",
    "# Create a Plotly plot  \n",
    "fig = px.line(  \n",
    "    mae_by_hour,  \n",
    "    x='pickup_hour',  \n",
    "    y='MAE',  \n",
    "    title='Mean Absolute Error (MAE) by Pickup Hour',  \n",
    "    labels={'pickup_hour': 'Pickup Hour', 'MAE': 'Mean Absolute Error'},  \n",
    "    markers=True  \n",
    ")  \n",
    "\n",
    "# Show the plot  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765143d-e386-4a2f-91eb-ecfa259f7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_by_hour[\"MAE\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4e80c-9fae-4152-93d6-f59c864d1d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
